<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>CALL Blog</title>
    <!-- Link to external CSS file -->
    <link rel="stylesheet" href="../../styles.css" />
    <link href="./recorder.css" rel="stylesheet" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  </head>

  <body>
    <div class="header">
      <div class="header-content">
        <div class="text-container">
          <h1>Computer Assisted language Learning</h1>
          <p>by Andrea Miró</p>
        </div>
      </div>
    </div>
    <div class="page-container">
      <article class="blog-post">
      <div class="container">
        <div class="center">
          <a href="../../technologies/speech-synthesis/synthesis.html" class="back-button">←Previous Post</a>
          <a href="../H5P/large-language-models.html" class="back-button">Next Post →</a>
          <a href="../../index.html" class="back-button">
            <i style="font-size:24px" class="fa"> &#xf015; </i>
          </a>
          <h2 style="font-family: cursive; font-size: xx-large;">Speech Recognition</h2>
          <h3>The effectiveness and evolution of speech recognition in CALL</h3>
  
          <p class="post-meta">Published on February 17, 2025</p>
  
          <img src="../../images/speech-recognition.svg" alt="Blog post image" class="post-image-speech-image" />
  
        </div>
  
        <p style="text-align: justify;">In recent years, Computer-Assisted Language Learning (CALL) has become one of the most valuable and rapidly evolving tools 
          in the field of language education. Along with speech synthesis, which I mentioned in my previous post, 
          speech recognition has also made significant progress within CALL, particularly over the last five years. 
          These developments have enabled more accurate, real-time transcription and feedback, allowing L2 learners to engage 
          with the target language and gain meaningful opportunities to refine their speaking skills, improve pronunciation, and gain confidence. 
        </p>

        <p style="text-align: justify;">Automatic Speech Recognition (ASR) technology uses machine learning and computer models, 
          which are trained on large collection of spoken language, to accurately convert speech into written text. A recent study by
          <a href="https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1210187/full"><b>Weina Sun (2023)</b>
          </a>
          showed that combining ASR technology with peer correction can significantly enhance pronunciation and speaking skills among L2 learners. 
          The research employed real-aloud tasks, spontaneous conversations, and IELTS speaking tests to assess the degree of accent, 
          intelligibility, and oral proficiency, while interviews captured participants’ impressions. Learners relied on peer support 
          to discuss and refine each other’s pronunciation, guided by the ASR output. 
          The results suggest that ASR provides learners with instant feedback on their speaking, enabling them to identify and correct errors 
          more effectively than teacher feedback alone, and target their areas of weakness. ASR feedback with peer support fosters more precise 
          pronunciation and greater speaking fluency, increasing learners’ motivation and confidence. However, the study also notes
          that ASR technologies don’t usually include phonetic representation, limiting learners’ understanding of how target sounds differ from their native language. 
        </p>

        <p style="text-align: justify;">Another example of how ASR technology improves pronunciation practice in the classroom is the study conducted by
          <a href="https://ijte.net/index.php/ijte/article/view/681/pdf"><b>Hsiao-Wen Hsu (2024)</b>
          </a> 
          In this case, learners used LearnMode, a CAPT (Computer-Assisted Pronunciation Training) platform that provides high-quality assessment 
          and immediate corrective feedback, allowing them to practice independently at any time. By applying the Technology Acceptance Model (TAM), 
          the study also evaluated learners’ intention to keep using the platform, showing positive results. 
          Ultimately, the immediate detection of errors and the opportunities for repeated practice improve speaking confidence 
          both in and out of the classroom, highlighting the importance of learner autonomy and personal practice.  
        </p>
        
        <p style="text-align: justify;">In a further research,
          <a href="https://www.tandfonline.com/doi/full/10.1080/17501229.2024.2315101#abstract"><b>Bashori, Van Hout, Strik and Cucchiarini (2024)</b>
          </a> 
         investigate how two different ASR systems, I love Indonesia (ILI) and NovoLearning (NOVO), can improve English pronunciation in an EFL context. 
         ILI provides global corrective feedback, whereas NOVO offers more detailed phonetic corrections. Through world and sentence pronunciation, 
         they measured phonetic distance, accent strength, and comprehensibility, finding learners’ improvements with both platforms.  
         However, NOVO’s explicit phonetic feedback was more effective with significantly better outcomes. 
         This support the idea that with individualized and immediate explicit phonetic feedback, students achieve more accurate pronunciation 
         and greater comprehensibility, especially when learners have limited classroom time or feel anxious about speaking. 
        </p>

        <p style="text-align: justify;">Despite all the progress and effectiveness of speech recognition applications for language learning,
          <a href="https://academic.oup.com/eltj/article/78/4/435/7749936"><b>Jeon, Lee and Coronel-Molina (2024)</b>
          </a> 
        show that although the evolving of AI chatbots can boost learners’ confidence and provide immediate feedback, 
        they often rely on standard native accent, as see with PengTalk in this study. This can reinforces monolingual norms and leaves out other English varieties. 
        Consequently, a more inclusive approach would better reflect global realities and how people use English today, helping learners feel comfortable 
        with the diversity of accents and speaking varieties they will encounter in real life. 
        </p>



     
  </article>
  </body>
</html>
